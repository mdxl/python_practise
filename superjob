import requests
from pprint import pprint
from bs4 import BeautifulSoup as bs


# https://russia.superjob.ru/vacancy/search/?keywords=python
# https://www.superjob.ru/vacancy/search/?keywords=Python&geo%5Bt%5D%5B0%5D=4
 
url = 'https://russia.superjob.ru/vacancy/search/ ? keywords=python'
 
#job = input('Введите желаемую должность ')
job = 'python'
main_url = 'https://russia.superjob.ru'
 
r_params = {'keywords': job,
           'page': '0',
           'geo':'%5Bt%5D%5B0%5D'}
 
r_headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.146 Safari/537.36'}
 
response = requests.get(main_url + '/vacancy/search', params = r_params, headers = r_headers)
soup = bs(response.text, 'html.parser')
cnt = 1
all_vacancies = []
while True:
    print(f'Страница {cnt} ')
    vacancy_list = soup.find_all ('div', {'class':'iJCa5 f-test-vacancy-item _1fma_ undefined _2nteL'})

    for vacancy in vacancy_list:
        vacancy_data = {}
        link = vacancy.find('a')
        vacancy_href = main_url + link.get('href')
        vacancy_name = link.getText()
        salary_data = vacancy.find('span', {'class': '_1OuF_ _1qw9T f-test-text-company-item-salary'})
        if salary_data is not None:
            vacancy_salary = salary_data.getText().replace('\xa0','')
            salary_text = ''.join(vacancy_salary.split()[:-1])
            vacancy_data['salary_cur'] = vacancy_salary.split()[-1].replace('.','')
            if salary_text.find('-') > -1:
                vacancy_data['salary_min'] = int(salary_text.split('-')[0])
                vacancy_data['salary_max'] = int(salary_text.split('-')[-1])
            elif salary_text.find('от') > -1:
                vacancy_data['salary_min'] = int(salary_text[2:])
                vacancy_data['salary_max'] = None
            elif salary_text.find('до') > -1:
                vacancy_data['salary_min'] = None
                vacancy_data['salary_max'] = int(salary_text[2:])
        else:
            vacancy_data['salary_min'] = None
            vacancy_data['salary_max'] = None
            vacancy_data['salary_cur'] = None
        vacancy_data['name'] = vacancy_name
        vacancy_data['href'] = vacancy_href
        #vacancy_data['salary'] = vacancy_salary
        all_vacancies.append(vacancy_data)
    pprint (all_vacancies [cnt*19])
    next_button = soup.find('a', {'class': 'f-test-link-Dalshe'})
    
    if next_button is None:
        break
    else:
        next_link = main_url + next_button.get('href')
        response = requests.get(next_link, headers = r_headers)
        soup = bs(response.text, 'html.parser')
        cnt +=1
  
